{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-05T10:28:05.783765Z",
     "start_time": "2024-11-05T10:28:01.282998Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 前処理とデータ準備"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "326808fef7a50ee"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:11<00:00, 861380.81it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 144207.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:03<00:00, 416298.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1000)>\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,),(0.5,))\n",
    "                                ])\n",
    "train_dataset = datasets.MNIST(root='./data',train=True,transform=transform,download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=True)\n",
    "\n",
    "# データローダーの作成\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=64, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T10:28:38.344904Z",
     "start_time": "2024-11-05T10:28:13.718209Z"
    }
   },
   "id": "661b8d05335616c8",
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CNNモデルの定義"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "bc2d248b9cb11127"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class CNN(nn.Module):# pytorchの基本モジュールを使うために継承\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # 1つ目の畳み込み層: 1入力チャンネル（グレースケール）、32出力チャンネル、カーネルサイズ3x3\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        # 2つ目の畳み込み層: 32入力チャンネル、64出力チャンネル\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        # プーリング層: 2x2のマックスプーリング\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        # ドロップアウト: 過学習防止のために50%を無効化\n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        # 全結合層1: 入力3136、出力128\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)  # 7x7はプーリング後のサイズ\n",
    "        # 全結合層2: 出力10（クラス数）\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 畳み込み1 -> ReLU -> プーリング\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        # 畳み込み2 -> ReLU -> プーリング\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # 平坦化\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        # 全結合1 -> ReLU -> ドロップアウト\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        # 全結合2 -> ソフトマックス\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T10:28:56.968178Z",
     "start_time": "2024-11-05T10:28:56.961895Z"
    }
   },
   "id": "797083e16ebf7930",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# モデルのインスタンス化と損失関数定義・最適化"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c614f6e8abb2ae49"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# モデルのインスタンス化\n",
    "model = CNN()\n",
    "\n",
    "# 損失関数と最適化手法\n",
    "criterion = nn.CrossEntropyLoss()  # 多クラス分類にクロスエントロピーを使用\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T10:28:58.729750Z",
     "start_time": "2024-11-05T10:28:58.710751Z"
    }
   },
   "id": "8a46bed90f32cceb",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 学習ループ定義"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fe4c438a3e0c663a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# トレーニング関数\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()  # モデルを訓練モードに\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()  # 勾配を初期化\n",
    "        output = model(data)  # フォワードパス\n",
    "        loss = criterion(output, target)  # 損失計算\n",
    "        loss.backward()  # バックプロパゲーション\n",
    "        optimizer.step()  # 最適化ステップ\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} ({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T10:29:01.636628Z",
     "start_time": "2024-11-05T10:29:01.631761Z"
    }
   },
   "id": "feebec6b7047992",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# テストループ定義"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "104e4f71594db79"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# テスト関数\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()  # モデルを評価モードに\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():  # テスト時には勾配を計算しない\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()  # バッチごとの損失\n",
    "            pred = output.argmax(dim=1, keepdim=True)  # 最大値のインデックスが予測\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} ({100. * correct / len(test_loader.dataset):.0f}%)\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T10:29:04.056442Z",
     "start_time": "2024-11-05T10:29:04.052037Z"
    }
   },
   "id": "9da24c937cd3fc5c",
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "# モデルのトレーニングとテスト"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2ea565a7aff549be"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.300625\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.251307\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.258510\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.198069\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.147742\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.124912\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.073015\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.039745\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.084744\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.057966\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9830/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.008916\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.052192\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.012884\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.118045\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.036073\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.140519\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.086967\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.090403\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.069874\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.115027\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9878/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.012842\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.022274\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.070772\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.147563\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.034781\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.039094\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.057559\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.061720\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.018180\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.008756\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9900/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.030609\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.166087\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.036107\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.129567\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.013452\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.021587\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.063344\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.102429\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.041696\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.152845\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.012212\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.032704\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.066724\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.003589\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.002306\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.006521\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.014912\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.006100\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.031295\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.034591\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9901/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.017579\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.003554\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.013614\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.003664\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.001646\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.001814\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.048549\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.015824\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.069066\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.008366\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9917/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.042868\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.041255\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.005000\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.004043\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.060831\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.004476\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.045914\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.010040\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.070164\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.063715\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9903/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.049212\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.014353\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.070893\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.027954\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.075871\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.053272\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.034247\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.008001\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.086089\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.000927\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.000473\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.002833\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.033239\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.011016\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.005931\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.004447\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.006494\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.010903\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.012542\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.001267\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9908/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.005858\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.009097\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.040359\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.003924\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.003130\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.001599\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.005116\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.091289\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.000263\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.133128\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9906/10000 (99%)\n"
     ]
    }
   ],
   "source": [
    "# GPUが使用可能なら使用\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# エポック数\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    train(model, device, train_loader, optimizer, epoch)\n",
    "    test(model, device, test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T10:30:50.874075Z",
     "start_time": "2024-11-05T10:29:05.479748Z"
    }
   },
   "id": "5eb5cd93384d4800",
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "source": [
    "# モデルの保存"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9e8d0c111cd1f8e6"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# モデルの全てのパラメータを取り出す\n",
    "model_params = model.state_dict()\n",
    "\n",
    "# CSVに保存（データの一部を切り捨て）\n",
    "with open('mnist_cnn_weights.csv', mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    \n",
    "    # ヘッダー行を追加（パラメータ名、形状、データの一部）\n",
    "    writer.writerow([\"Parameter Name\", \"Shape\", \"Sample Values (First 10)\"])\n",
    "    \n",
    "    for key, value in model_params.items():\n",
    "        # GPU上にあるテンソルをCPUに移動してからnumpyに変換\n",
    "        value_cpu = value.cpu().numpy()\n",
    "        \n",
    "        # 各パラメータの先頭10個の値だけを保存（1次元に変換）\n",
    "        flat_values = value_cpu.flatten()[:10]  # 先頭10個を取得\n",
    "        \n",
    "        # パラメータ名、形状、データの一部をCSVに保存\n",
    "        writer.writerow([key, value_cpu.shape, flat_values.tolist()])\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T11:02:34.256235Z",
     "start_time": "2024-11-05T11:02:34.244697Z"
    }
   },
   "id": "859e54dde127b146",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.jpg: 1\n",
      "3.png: 6\n",
      "5.png: 5\n",
      "9.jpg: 3\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "# 複数画像の手書き数字を推論する関数\n",
    "def predict_multiple_digits(model, image_paths, device):\n",
    "    model.eval()  # モデルを評価モードに\n",
    "    predictions = []  # 結果を保存するリスト\n",
    "\n",
    "    # 画像の前処理設定\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((28, 28)),  # MNISTのサイズにリサイズ\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    # 画像をループ処理\n",
    "    for image_path in image_paths:\n",
    "        # 画像を読み込む\n",
    "        image = Image.open(image_path).convert('L')  # グレースケール画像に変換\n",
    "\n",
    "        # 画像の前処理\n",
    "        image = transform(image).unsqueeze(0)  # バッチサイズ1を追加\n",
    "\n",
    "        # 画像をデバイスに転送\n",
    "        image = image.to(device)\n",
    "\n",
    "        # 勾配を計算しない設定で推論\n",
    "        with torch.no_grad():\n",
    "            output = model(image)\n",
    "            pred = output.argmax(dim=1)  # 予測されたクラスを取得\n",
    "            predictions.append((os.path.basename(image_path), pred.item()))  # 画像名と予測結果をリストに保存\n",
    "\n",
    "    return predictions  # 予測結果を返す\n",
    "\n",
    "# 画像ファイルがあるディレクトリのパス\n",
    "image_dir = 'image_directory'  # 画像が保存されているディレクトリのパス\n",
    "\n",
    "# ディレクトリ内の画像ファイルのパスを取得\n",
    "image_paths = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith(('png', 'jpg', 'jpeg'))]\n",
    "\n",
    "# 複数画像の予測を実行\n",
    "predictions = predict_multiple_digits(model, image_paths, device)\n",
    "\n",
    "# 予測結果を「画像名：予測した数字」の形式で表示\n",
    "for image_name, predicted_digit in predictions:\n",
    "    print(f'{image_name}: {predicted_digit}')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-05T11:23:09.721240Z",
     "start_time": "2024-11-05T11:23:09.685194Z"
    }
   },
   "id": "dadf1a8002c8b981",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9bdcd8eefa4dbb93"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
